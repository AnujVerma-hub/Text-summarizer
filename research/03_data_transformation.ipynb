{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0d40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef50c9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Text-summarizer\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6fe190",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dcad33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Text-summarizer'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a97a0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in d:\\text-summarizer\\texts\\lib\\site-packages (2025.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in d:\\text-summarizer\\texts\\lib\\site-packages (2.13.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: xxhash in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\text-summarizer\\texts\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\text-summarizer\\texts\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\text-summarizer\\texts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\text-summarizer\\texts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in d:\\text-summarizer\\texts\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in d:\\text-summarizer\\texts\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\text-summarizer\\texts\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\text-summarizer\\texts\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\text-summarizer\\texts\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: colorama in d:\\text-summarizer\\texts\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\text-summarizer\\texts\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\text-summarizer\\texts\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\text-summarizer\\texts\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\text-summarizer\\texts\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "Using cached pyarrow-21.0.0-cp311-cp311-win_amd64.whl (26.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, pyarrow, datasets\n",
      "\n",
      "  Attempting uninstall: tqdm\n",
      "\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "  Attempting uninstall: pyarrow\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "  Attempting uninstall: datasets\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "    Found existing installation: datasets 2.13.1\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "    Uninstalling datasets-2.13.1:\n",
      "   ------------- -------------------------- 1/3 [pyarrow]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "      Successfully uninstalled datasets-2.13.1\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   -------------------------- ------------- 2/3 [datasets]\n",
      "   ---------------------------------------- 3/3 [datasets]\n",
      "\n",
      "Successfully installed datasets-4.1.1 pyarrow-21.0.0 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Text-summarizer\\texts\\Lib\\site-packages\\~-arrow'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade fsspec\n",
    "%pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df43927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    tokenizer_name: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf7b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textSummarizer.constants import *\n",
    "from textSummarizer.utils.common import read_yaml, create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0caeeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            tokenizer_name = config.tokenizer_name\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d88219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Text-summarizer\\texts\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from textSummarizer.logging import logger\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174fc0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      ".\\artifacts\\data_ingestion\\samsum_dataset\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(\"artifacts/data_ingestion/samsum_dataset\"))\n",
    "print(os.path.exists(\"artifacts/data_ingestion\"))\n",
    "for root,dirs,files in os.walk(\".\",topdown=True):\n",
    "    if\"samsum_dataset\" in dirs:\n",
    "        print(os.path.join(root, \"samsum_dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b56ebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'dialogue', 'summary'],\n",
      "    num_rows: 819\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_disk(\"artifacts/data_ingestion/samsum_dataset/test\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f839937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)\n",
    "\n",
    "\n",
    "    \n",
    "    def convert_examples_to_features(self,example_batch):\n",
    "        input_encodings = self.tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
    "        \n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "            target_encodings = self.tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
    "            \n",
    "        return {\n",
    "            'input_ids' : input_encodings['input_ids'],\n",
    "            'attention_mask': input_encodings['attention_mask'],\n",
    "            'labels': target_encodings['input_ids']\n",
    "        }\n",
    "    \n",
    "\n",
    "    def convert(self):\n",
    "        abs_path = os.path.abspath(self.config.data_path)\n",
    "        print(f\"The root directory is :{self.config.root_dir}\")\n",
    "        print(f\"The data path is:{self.config.data_path}\")\n",
    "        print(f\"The absolute path is:{abs_path}\")\n",
    "        dataset_samsum = load_from_disk(abs_path)\n",
    "        dataset_samsum_pt = dataset_samsum.map(self.convert_examples_to_features, batched = True)\n",
    "        dataset_samsum_pt.save_to_disk(os.path.join(self.config.root_dir,\"samsum_dataset\"))\n",
    "        print(self.config.root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af6bd9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_dict.json', 'test', 'train', 'validation']\n"
     ]
    }
   ],
   "source": [
    "path = os.path.abspath(\"artifacts/data_ingestion/samsum_dataset\")\n",
    "print(os.listdir(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f645cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-21 09:44:01,301: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-09-21 09:44:01,308: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-09-21 09:44:01,308: INFO: common: created directory at: artifacts]\n",
      "[2025-09-21 09:44:01,308: INFO: common: created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Text-summarizer\\texts\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root directory is :artifacts/data_transformation\n",
      "The data path is:artifacts/data_ingestion/samsum_dataset\n",
      "The absolute path is:d:\\Text-summarizer\\artifacts\\data_ingestion\\samsum_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]d:\\Text-summarizer\\texts\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 14732/14732 [00:05<00:00, 2696.79 examples/s]\n",
      "Map: 100%|██████████| 819/819 [00:00<00:00, 2375.13 examples/s]\n",
      "Map: 100%|██████████| 818/818 [00:00<00:00, 2603.33 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 14732/14732 [00:00<00:00, 151949.30 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 819/819 [00:00<00:00, 51656.94 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 818/818 [00:00<00:00, 48703.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts/data_transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.convert()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "texts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
